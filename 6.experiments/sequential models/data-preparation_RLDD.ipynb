{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# multivariate multi-step stacked lstm example\nimport numpy as np\nfrom numpy import array\nfrom numpy import hstack\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nimport pandas as pd\nimport pickle as pkl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RLDD\nrldd_scaled = pd.read_pickle('../input/rlddandmerged/rldd_normalized_scaled.pkl')\n\n# get video info from other dataset\nrldd_UNscaled = pd.read_pickle('../input/rlddandmerged/rldd_normalized.pkl')\nvideo_info_df2 = rldd_UNscaled.iloc[:,0:4]\n\n# and concat video info with scaled df\nrldd = pd.concat([video_info_df2, rldd_scaled], axis=1)\n\n# fix drowsiness column\nrldd[\"DROWSINESS\"] = rldd.loc[:, \"DROWSINESS\"].map({0:0, 0.5:1, 1:2})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add rldd videos to lists\ng = rldd.groupby([\"fold\", \"subject\", \"videoname\"])\nlen(g.groups.keys())\n\nrldd_train_list = []\nrldd_test_list = []\n\nfor key in g.groups.keys():\n    print(key)\n    if key[1] in ['57', '58', '59', '60']:\n        rldd_test_list.append(g.get_group(key).iloc[:,4:])\n    else:\n        rldd_train_list.append(g.get_group(key).iloc[:,4:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split a multivariate sequence into samples\ndef split_sequences(dataset_arr, n_steps_in, n_steps_out):\n    X, y = list(), list()\n    for i in range(len(dataset_arr)):\n        # find the end of this pattern\n        end_ix = i + n_steps_in\n        out_end_ix = end_ix + n_steps_out\n        # check if we are beyond the dataset\n        if out_end_ix > len(dataset_arr) or end_ix > len(dataset_arr):\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = dataset_arr[i:end_ix, :-1], dataset_arr[end_ix:out_end_ix, -1]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split sequences for rldd train\nrldd_train_seq_list_X=[]\nrldd_train_seq_list_y=[]\n\nn_steps_in, n_steps_out = 150, 60\n\nfor video_df in rldd_train_list:\n    video_arr=np.array(video_df)\n    # covert into input/output\n    X, y = split_sequences(video_arr, n_steps_in, n_steps_out)\n    if len(X)==0 or len(y)==0:\n        continue\n    rldd_train_seq_list_X.append(X)\n    rldd_train_seq_list_y.append(y)\n\n# concat lists\nrldd_train_X = np.concatenate(rldd_train_seq_list_X, axis=0)\nrldd_train_y = np.concatenate(rldd_train_seq_list_y, axis=0)\n\npkl.dump(rldd_train_X, open(\"rldd_train_X\", 'wb'))\npkl.dump(rldd_train_y, open(\"rldd_train_y\", 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split sequences for rldd test\nrldd_test_seq_list_X=[]\nrldd_test_seq_list_y=[]\n\nn_steps_in, n_steps_out = 150, 60\n\nfor video_df in rldd_test_list:\n    video_arr=np.array(video_df)\n    # covert into input/output\n    X, y = split_sequences(video_arr, n_steps_in, n_steps_out)\n    if len(X)==0 or len(y)==0:\n        continue\n    rldd_test_seq_list_X.append(X)\n    rldd_test_seq_list_y.append(y)\n\n# concat lists\nrldd_test_X = np.concatenate(rldd_test_seq_list_X, axis=0)\nrldd_test_y = np.concatenate(rldd_test_seq_list_y, axis=0)\n\npkl.dump(rldd_test_X, open(\"rldd_test_X\", 'wb'))\npkl.dump(rldd_test_y, open(\"rldd_test_y\", 'wb'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}